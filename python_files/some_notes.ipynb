{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# (1) Detect Human\n",
    "\n",
    "This function takes a path to an image as input & returns \"True\" if there's a detected face.  The plan is to replace this Python implementation with the iOS implementation [here](https://developer.apple.com/documentation/vision/vndetectfacerectanglesrequest).\n",
    "\n",
    "### notes on iOS\n",
    "\n",
    "- Seems straightforward to use the documentation to accomplish this functionality! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def face_detector(img_path):\n",
    "    \"\"\" returns \"True\" if face is detected in image stored at img_path \"\"\"\n",
    "    import cv2\n",
    "    img = cv2.imread(img_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "    faces = face_cascade.detectMultiScale(gray)\n",
    "    return len(faces) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# (2) Detect Dog\n",
    "\n",
    "The ResNet-50 model takes a pre-processed image as input and outputs the probability that the image contains an object from each of the 1000 categories here.\n",
    "\n",
    "The `path_to_tensor` function preprocesses the image.  In Python/Keras, this is a necessary step before the model will accept the image.\n",
    "\n",
    "The `dog_detector` function takes the preprocessed image as input.  It then supplies the pre-processed image to ResNet-50, which returns a (probability) vector with 1000 entries (where the $i$-th entry in the vector is a number between 0 and 1 that yields the probability that the image depicts the $i$-th object category).  The categories that are different dog types should correspond to entries 151-268 in the vector, inclusive.\n",
    "\n",
    "### notes on iOS\n",
    "\n",
    "- We need to preprocess the image:\n",
    "    - Subtract a fixed pixel from every pixel in the image.  If the pixel is expressed in RGB, with red, green, and blue intensities taking on values $[0,255]$, then we need to subtract $[103.939, 116.779, 123.68]$ from every pixel.\n",
    "    - Convert the image from RGB to BGR.\n",
    "    - Resize image to 224 x 224 (In Keras, the image needs to be reshaped to a tensor with dimensions `1 x 224 x 224 x 3`, before ResNet-50 will accept the image.  Here, `3` corresponds to the number of color channels (BGR) ... But it looks like for iOS, the image just needs to be a color image that's 224 x 224.)\n",
    "- In my understanding, the Core ML-compatible ResNet-50 model that is supplied **in the documentation** should return a 1000-dimensional probability vector.  In this case, the dog detector function should be straightforward to implement:\n",
    "    - We need only take the arg max of that probability vector, which yields the predicted object category (... the arg max will be a value between 0 and 999, inclusive).  \n",
    "    - The image is deemed by the model to contain a dog if the arg max lies between 151 and 268, inclusive.  Here's the full list of categories: [link](https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def path_to_tensor(img_path):\n",
    "    \"\"\" preprocessing - resize the image, subtract mean pixel, change dimensionality of input \"\"\"\n",
    "    from keras.preprocessing import image   \n",
    "    import numpy as np\n",
    "    from keras.applications.resnet50 import preprocess_input\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    return preprocess_input(x)\n",
    "\n",
    "def dog_detector(proc_tensor):\n",
    "    \"\"\" returns \"True\" if a dog is detected in the image stored at img_path \"\"\"\n",
    "    from keras.applications.resnet50 import preprocess_input, ResNet50\n",
    "    import numpy as np\n",
    "    ResNet50_model = ResNet50(weights='imagenet')\n",
    "    prediction = np.argmax(ResNet50_model.predict(proc_tensor))\n",
    "    return ((prediction <= 268) & (prediction >= 151))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# (3) Get Breed\n",
    "\n",
    "It will take some extra effort to make the student model work (we should talk about this by video, I think).  For now, I think that the best bet is to get a pipeline working that uses just the ResNet-50 model for predicting dog breed.  This model already exists in the iOS documentation ...\n",
    "\n",
    "The idea would be:\n",
    "- if a human is detected in Step 1, return the dog that it is predicted to look most like.  \n",
    "- if a dog is detected in Step 2, return the corresponding breed of dog\n",
    "\n",
    "... I think that this first attempt would be easily replaced later with the student's model.\n",
    "\n",
    "### notes on iOS\n",
    "\n",
    "For now, I think that it's possible to simply return the most predicted dog breed from the ResNet-50 model that exists in the iOS documentation ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def ResNet50_model_predict_breed(proc_tensor):\n",
    "    \"\"\" uses the ResNet-50 model from the documentation to predict dog breed \"\"\"\n",
    "    from keras.applications.resnet50 import ResNet50, decode_predictions\n",
    "    ResNet50_model = ResNet50(weights='imagenet')\n",
    "    return decode_predictions(ResNet50_model.predict(proc_tensor), top=0)[0][0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Full Pipeline: (1) + (2) + (3) (w/ ResNet-50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def full_pipeline(img_path):\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "    # get the tensor that will be used to predict breed\n",
    "    proc_tensor = path_to_tensor(img_path)\n",
    "    # print the appropriate statements\n",
    "    if face_detector(img_path):\n",
    "        print('hello, human! you vaguely resemble ...')\n",
    "    elif dog_detector(proc_tensor):\n",
    "        print('hello, dog! you look like a ...')\n",
    "    else:\n",
    "        print('hmm, neither human nor dog! but it reminds me of ...')\n",
    "    print(ResNet50_model_predict_breed(proc_tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# And that's it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello, human! you vaguely resemble ...\n",
      "stole\n"
     ]
    }
   ],
   "source": [
    "full_pipeline('test_images/human.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello, dog!  you look like a ...\n",
      "Boston_bull\n"
     ]
    }
   ],
   "source": [
    "full_pipeline('test_images/dog.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the ResNet-50 Model for iOS (as HDF5 file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from keras.applications.resnet50 import ResNet50\n",
    "# model = ResNet50(weights='imagenet')\n",
    "# model.save('ResNet50_for_iOS.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Saving the Student's Model for iOS (as HDF5 file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers in student_model\n",
      "<keras.layers.pooling.GlobalAveragePooling2D object at 0x165292400>\n",
      "<keras.layers.core.Dense object at 0x1516f2ac8>\n",
      "<keras.layers.core.Dropout object at 0x16ac4aa20>\n",
      "<keras.layers.core.Dense object at 0x16ac4a320>\n",
      "\n",
      " layers in student_model_stump\n",
      "<keras.layers.pooling.GlobalAveragePooling2D object at 0x165388be0>\n",
      "<keras.layers.core.Dense object at 0x165373940>\n",
      "<keras.layers.core.Dropout object at 0x165388f98>\n",
      "<keras.layers.core.Dense object at 0x165388e80>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 133)               68229     \n",
      "=================================================================\n",
      "Total params: 1,117,317\n",
      "Trainable params: 1,117,317\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.models import load_model, Model\n",
    "from keras.layers import GlobalAveragePooling2D, Dropout, Dense\n",
    "\n",
    "resnet_50_model = ResNet50(weights='imagenet', include_top=False)\n",
    "last = resnet_50_model.output\n",
    "\n",
    "x = GlobalAveragePooling2D()(last)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "preds = Dense(133, activation='softmax')(x)\n",
    "\n",
    "student_model = Model(resnet_50_model.input, preds)\n",
    "\n",
    "# print layers in student_model\n",
    "print('layers in student_model')\n",
    "for layer in student_model.layers[-4:]:\n",
    "    print(layer)\n",
    "\n",
    "# print layers in student_model_stump\n",
    "print('\\n layers in student_model_stump')\n",
    "student_model_stump = load_model('student_model_stump.h5')\n",
    "for layer in student_model_stump.layers:\n",
    "    print(layer)\n",
    "    \n",
    "student_model_stump.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "student_model.layers[-4].set_weights(student_model_stump.layers[0].get_weights())\n",
    "student_model.layers[-3].set_weights(student_model_stump.layers[1].get_weights())\n",
    "student_model.layers[-2].set_weights(student_model_stump.layers[2].get_weights())\n",
    "student_model.layers[-1].set_weights(student_model_stump.layers[3].get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "student_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# student_model.save('student_model_for_iOS.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Pipeline: (1) + (2) + (3) (w/ student model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom glob import glob\\ndog_names = [item[58:-1] for item in sorted(glob(\"../../CNN content/dog-project-private/dogImages/train/*/\"))]\\nprint(dog_names)\\n\\nthefile = open(\\'dog_names.txt\\', \\'w\\')\\nfor item in dog_names:\\n    thefile.write(\"%s\\n\" % item)\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for writing dog names into txt file\n",
    "'''\n",
    "from glob import glob\n",
    "dog_names = [item[58:-1] for item in sorted(glob(\"../../CNN content/dog-project-private/dogImages/train/*/\"))]\n",
    "print(dog_names)\n",
    "\n",
    "thefile = open('dog_names.txt', 'w')\n",
    "for item in dog_names:\n",
    "    thefile.write(\"%s\\n\" % item)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def student_model_predict_breed(proc_tensor):\n",
    "    \"\"\" uses the student's model to predict dog breed \"\"\"\n",
    "    from keras.models import load_model\n",
    "    import numpy as np\n",
    "    student_model = load_model('student_model.h5')\n",
    "    text_file = open('dog_names.txt', 'r')\n",
    "    dog_names = text_file.read().split('\\n')\n",
    "    return dog_names[np.argmax(student_model.predict(proc_tensor))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def full_pipeline_student(img_path):\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "    # get the tensor that will be used to predict breed\n",
    "    proc_tensor = path_to_tensor(img_path)\n",
    "    # print the appropriate statements\n",
    "    if face_detector(img_path):\n",
    "        print('hello, human! you vaguely resemble ...')\n",
    "    elif dog_detector(proc_tensor):\n",
    "        print('hello, dog! you look like a ...')\n",
    "    else:\n",
    "        print('hmm, neither human nor dog! but it reminds me of ...')\n",
    "    print(student_model_predict_breed(proc_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello, human! you vaguely resemble ...\n",
      "Kerry_blue_terrier\n"
     ]
    }
   ],
   "source": [
    "full_pipeline_student('test_images/human.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello, dog!  you look like a ...\n",
      "Boston_terrier\n"
     ]
    }
   ],
   "source": [
    "full_pipeline_student('test_images/dog.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
