{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# (1) Detect Human\n",
    "\n",
    "This function takes a path to an image as input & returns \"True\" if there's a detected face.  The plan is to replace this Python implementation with the iOS implementation [here](https://developer.apple.com/documentation/vision/vndetectfacerectanglesrequest).\n",
    "\n",
    "### notes on iOS\n",
    "\n",
    "- Seems straightforward to use the documentation to accomplish this functionality! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def face_detector(img_path):\n",
    "    \"\"\" returns \"True\" if face is detected in image stored at img_path \"\"\"\n",
    "    import cv2\n",
    "    img = cv2.imread(img_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "    faces = face_cascade.detectMultiScale(gray)\n",
    "    return len(faces) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# (2) Detect Dog\n",
    "\n",
    "The ResNet-50 model takes a pre-processed image as input and outputs the probability that the image contains an object from each of the 1000 categories here.\n",
    "\n",
    "The `path_to_tensor` function preprocesses the image.  In Python/Keras, this is a necessary step before the model will accept the image.\n",
    "\n",
    "The `dog_detector` function takes the preprocessed image as input.  It then supplies the pre-processed image to ResNet-50, which returns a (probability) vector with 1000 entries (where the $i$-th entry in the vector is a number between 0 and 1 that yields the probability that the image depicts the $i$-th object category).  The categories that are different dog types should correspond to entries 151-268 in the vector, inclusive.\n",
    "\n",
    "### notes on iOS\n",
    "\n",
    "- We still need to figure out how to preprocess the image:\n",
    "    - resize every image to 224 x 224 pixels\n",
    "    - subtract a fixed pixel from every pixel in the image.  If the pixel is expressed in RGB, with red, green, and blue intensities taking on values $[0,255]$, then we need to subtract $[103.939, 116.779, 123.68]$ from every pixel.\n",
    "    - In Keras, the image also needs to be reshaped to a tensor with dimensions `1 x 224 x 224 x 3`, before ResNet-50 will accept the image.  Here, `3` corresponds to the number of color channels (RGB).  It is not yet clear to me if this is the case for the CoreML-compatible model.\n",
    "- In my understanding, the Core ML-compatible ResNet-50 model that is supplied **in the documentation** should return a 1000-dimensional probability vector.  In this case, the dog detector function should be straightforward to implement:\n",
    "    - We need only take the arg max of that probability vector, which yields the predicted object category (... the arg max will be a value between 0 and 999, inclusive).  \n",
    "    - The image is deemed by the model to contain a dog if the arg max lies between 151 and 268, inclusive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def path_to_tensor(img_path):\n",
    "    \"\"\" preprocessing - resize the image, subtract mean pixel, change dimensionality of input \"\"\"\n",
    "    from keras.preprocessing import image   \n",
    "    import numpy as np\n",
    "    from keras.applications.resnet50 import preprocess_input\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    return preprocess_input(x)\n",
    "\n",
    "def dog_detector(proc_tensor):\n",
    "    \"\"\" returns \"True\" if a dog is detected in the image stored at img_path \"\"\"\n",
    "    from keras.applications.resnet50 import preprocess_input, ResNet50\n",
    "    import numpy as np\n",
    "    ResNet50_model = ResNet50(weights='imagenet')\n",
    "    prediction = np.argmax(ResNet50_model.predict(proc_tensor))\n",
    "    return ((prediction <= 268) & (prediction >= 151))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# (3) Get Breed\n",
    "\n",
    "It will take some extra effort to make the student model work (we should talk about this by video, I think).  For now, I think that the best bet is to get a pipeline working that uses just the ResNet-50 model for predicting dog breed.  This model already exists in the iOS documentation ...\n",
    "\n",
    "The idea would be:\n",
    "- if a human is detected in Step 1, return the dog that it is predicted to look most like.  \n",
    "- if a dog is detected in Step 2, return the corresponding breed of dog\n",
    "\n",
    "... I think that this first attempt would be easily replaced later with the student's model.\n",
    "\n",
    "### notes on iOS\n",
    "\n",
    "For now, I think that it's possible to simply return the most predicted dog breed from the ResNet-50 model that exists in the iOS documentation ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def ResNet50_model_predict_breed(proc_tensor):\n",
    "    \"\"\" uses the ResNet-50 model from the documentation to predict dog breed \"\"\"\n",
    "    from keras.applications.resnet50 import ResNet50, decode_predictions\n",
    "    ResNet50_model = ResNet50(weights='imagenet')\n",
    "    return decode_predictions(ResNet50_model.predict(proc_tensor), top=0)[0][0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Full Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def full_pipeline(img_path):\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "    # get the tensor that will be used to predict breed\n",
    "    proc_tensor = path_to_tensor(img_path)\n",
    "    # print the appropriate statements\n",
    "    if face_detector(img_path):\n",
    "        print('hello, human! you vaguely resemble ...')\n",
    "    elif dog_detector(proc_tensor):\n",
    "        print('hello, dog!  you look like a ...')\n",
    "    else:\n",
    "        print('hmm, neither human nor dog! but it remind me of ...')\n",
    "    print(ResNet50_model_predict_breed(proc_tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# And that's it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello, human! you vaguely resemble ...\n",
      "stole\n"
     ]
    }
   ],
   "source": [
    "full_pipeline('test_images/human.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello, dog!  you look like a ...\n",
      "Boston_bull\n"
     ]
    }
   ],
   "source": [
    "full_pipeline('test_images/dog.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toward student's model (coming soon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_Resnet50(proc_tensor):\n",
    "    \"\"\" this is used before the student's model \"\"\"\n",
    "    from keras.applications.resnet50 import ResNet50\n",
    "    ResNet50_model_notop = ResNet50(weights='imagenet', include_top=False)\n",
    "    return ResNet50_model_notop.predict(proc_tensor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
